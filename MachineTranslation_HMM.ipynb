{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Fbfhqh9abEjr"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# BLOCK 1: INSTALL REQUIRED LIBRARIES\n",
        "# This installs dataset loading and BLEU evaluation tools.\n",
        "# ============================================================\n",
        "!pip install datasets nltk sacrebleu -q\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# BLOCK 2: IMPORT REQUIRED LIBRARIES\n",
        "# ============================================================\n",
        "import math\n",
        "from collections import defaultdict, Counter\n",
        "from datasets import load_dataset\n",
        "import sacrebleu\n"
      ],
      "metadata": {
        "id": "h3-SacIvcqy3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# BLOCK 3: LOAD DATASET AND CREATE 80/20 SPLIT\n",
        "# ============================================================\n",
        "dataset = load_dataset(\"bentrevett/multi30k\")\n",
        "\n",
        "split_dataset = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "train_data = split_dataset[\"train\"]\n",
        "test_data = split_dataset[\"test\"]\n"
      ],
      "metadata": {
        "id": "mr0hc2uWcspl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# BLOCK 4: DEFINE SIMPLE TOKENIZER\n",
        "# This splits sentences by whitespace and converts to lowercase.\n",
        "# ============================================================\n",
        "def tokenize(sentence):\n",
        "    return sentence.lower().split()\n"
      ],
      "metadata": {
        "id": "MK0xkwGmcuwc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# BLOCK 5: BUILD HMM COUNT TABLES\n",
        "# ============================================================\n",
        "transition_counts = defaultdict(Counter)\n",
        "emission_counts = defaultdict(Counter)\n",
        "state_counts = Counter()\n",
        "\n",
        "train_limit = min(5000, len(train_data))\n",
        "\n",
        "for i in range(train_limit):\n",
        "\n",
        "    example = train_data[i]\n",
        "\n",
        "    en_tokens = tokenize(example[\"en\"])\n",
        "    de_tokens = tokenize(example[\"de\"])\n",
        "\n",
        "    min_len = min(len(en_tokens), len(de_tokens))\n",
        "\n",
        "    for j in range(min_len):\n",
        "        state = de_tokens[j]\n",
        "        obs = en_tokens[j]\n",
        "\n",
        "        emission_counts[state][obs] += 1\n",
        "        state_counts[state] += 1\n",
        "\n",
        "        if j > 0:\n",
        "            prev_state = de_tokens[j-1]\n",
        "            transition_counts[prev_state][state] += 1\n"
      ],
      "metadata": {
        "id": "9XB11cERcyVI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# BLOCK 6: CONVERT COUNTS TO PROBABILITIES\n",
        "# Using Laplace smoothing to avoid zero probabilities\n",
        "# ============================================================\n",
        "transition_prob = {}\n",
        "emission_prob = {}\n",
        "\n",
        "vocab_size = len(state_counts)\n",
        "\n",
        "# Transition probabilities\n",
        "for prev_state in transition_counts:\n",
        "    total = sum(transition_counts[prev_state].values())\n",
        "    transition_prob[prev_state] = {\n",
        "        state: (count + 1) / (total + vocab_size)\n",
        "        for state, count in transition_counts[prev_state].items()\n",
        "    }\n",
        "\n",
        "# Emission probabilities\n",
        "for state in emission_counts:\n",
        "    total = state_counts[state]\n",
        "    emission_prob[state] = {\n",
        "        obs: (count + 1) / (total + vocab_size)\n",
        "        for obs, count in emission_counts[state].items()\n",
        "    }\n"
      ],
      "metadata": {
        "id": "WVf61sbac0dk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# BLOCK 7: DEFINE TRANSLATION FUNCTION\n",
        "# ============================================================\n",
        "def translate_sentence(en_sentence):\n",
        "    en_tokens = tokenize(en_sentence)\n",
        "    translated = []\n",
        "\n",
        "    for word in en_tokens:\n",
        "        best_state = None\n",
        "        best_prob = 0\n",
        "\n",
        "        for state in emission_prob:\n",
        "            prob = emission_prob[state].get(word, 0)\n",
        "            if prob > best_prob:\n",
        "                best_prob = prob\n",
        "                best_state = state\n",
        "\n",
        "        if best_state:\n",
        "            translated.append(best_state)\n",
        "        else:\n",
        "            translated.append(\"<unk>\")\n",
        "\n",
        "    return \" \".join(translated)\n"
      ],
      "metadata": {
        "id": "W08sIAMgc2PF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# BLOCK 8: GENERATE PREDICTIONS\n",
        "# ============================================================\n",
        "predictions = []\n",
        "references = []\n",
        "\n",
        "test_limit = min(500, len(test_data))\n",
        "\n",
        "for i in range(test_limit):\n",
        "\n",
        "    example = test_data[i]   # âœ… Always returns dictionary\n",
        "\n",
        "    pred = translate_sentence(example[\"en\"])\n",
        "    ref = example[\"de\"]\n",
        "\n",
        "    predictions.append(pred)\n",
        "    references.append([ref])\n",
        "\n"
      ],
      "metadata": {
        "id": "GAjJLnwKc3o-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# BLOCK 9: COMPUTE BLEU SCORE\n",
        "# ============================================================\n",
        "import sacrebleu\n",
        "\n",
        "# Make sure predictions and references are not empty\n",
        "if len(predictions) == 0:\n",
        "    print(\"No predictions generated.\")\n",
        "else:\n",
        "    bleu = sacrebleu.corpus_bleu(\n",
        "        predictions,\n",
        "        [ [ref[0] for ref in references] ]  # correct format\n",
        "    )\n",
        "\n",
        "    print(\"BLEU Score:\", bleu.score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPwi6zm2dfYK",
        "outputId": "26476761-54b8-4a36-bb09-eb6837f36a66"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.6706746022173007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# BLOCK 10: COMPUTE LOSS AND PERPLEXITY\n",
        "# ============================================================\n",
        "log_likelihood = 0\n",
        "total_words = 0\n",
        "\n",
        "for pred, ref in zip(predictions, references):\n",
        "\n",
        "    ref_tokens = tokenize(ref[0])\n",
        "    pred_tokens = tokenize(pred)\n",
        "\n",
        "    min_len = min(len(ref_tokens), len(pred_tokens))\n",
        "\n",
        "    for i in range(min_len):\n",
        "        state = ref_tokens[i]\n",
        "        obs = pred_tokens[i]\n",
        "\n",
        "        prob = emission_prob.get(state, {}).get(obs, 1e-6)\n",
        "        log_likelihood += math.log(prob)\n",
        "        total_words += 1\n",
        "\n",
        "loss = -log_likelihood / total_words\n",
        "perplexity = math.exp(loss)\n",
        "\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Perplexity:\", perplexity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-F5vUKnc5hS",
        "outputId": "b4c25967-2d5c-4055-b440-1cfdbe7bc182"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 13.294003644627962\n",
            "Perplexity: 593625.3317038155\n"
          ]
        }
      ]
    }
  ]
}